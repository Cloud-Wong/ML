{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习练习 3 - 多类分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该代码涵盖了基于Python的解决方案，用于Coursera机器学习课程的第三个编程练习。 有关详细说明和方程式，请参阅[exercise text](ex3.pdf)。\n",
    "\n",
    "\n",
    "代码修改并注释：黄海广，haiguang2000@qq.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "对于此练习，我们将使用逻辑回归来识别手写数字（0到9）。 我们将扩展我们在练习2中写的逻辑回归的实现，并将其应用于一对一的分类。 让我们开始加载数据集。 它是在MATLAB的本机格式，所以要加载它在Python，我们需要使用一个SciPy工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape, data['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的，我们已经加载了我们的数据。图像在martix X中表示为400维向量（其中有5,000个）。 400维“特征”是原始20 x 20图像中每个像素的灰度强度。类标签在向量y中作为表示图像中数字的数字类。\n",
    "\n",
    "\n",
    "第一个任务是将我们的逻辑回归实现修改为完全向量化（即没有“for”循环）。这是因为向量化代码除了简洁外，还能够利用线性代数优化，并且通常比迭代代码快得多。但是，如果从练习2中看到我们的代价函数已经完全向量化实现了，所以我们可以在这里重复使用相同的实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sigmoid 函数\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： \\\\[g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}\\\\] \n",
    "合起来，我们得到逻辑回归模型的假设函数： \n",
    "\t\\\\[{{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta }^{T}}X}}}\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代价函数：\n",
    "$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    reg = (learningRate / (2 * len(X))) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "    return np.sum(first - second) / len(X) + reg\n",
    "def lrCostFunction(theta,x,y,lmd):\n",
    "    m = x.shape[0]\n",
    "    theta = theta.reshape(-1,1)\n",
    "    first = np.log(sigmoid(x@theta))*y\n",
    "    second = np.log(1-sigmoid(x@theta))*(1-y)\n",
    "    theta_1 = theta[1:,:]\n",
    "    unregcost = -np.sum(first + second)/m\n",
    "    reg = lmd*theta_1.T@theta_1/(2*m)\n",
    "    return unregcost+reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对${{\\theta }_{0}}$ 进行正则化，所以梯度下降算法将分两种情形：\n",
    "\\begin{align}\n",
    "  & Repeat\\text{ }until\\text{ }convergence\\text{ }\\!\\!\\{\\!\\!\\text{ } \\\\ \n",
    " & \\text{     }{{\\theta }_{0}}:={{\\theta }_{0}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}}]x_{_{0}}^{(i)}} \\\\ \n",
    " & \\text{     }{{\\theta }_{j}}:={{\\theta }_{j}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}}]x_{j}^{(i)}}+\\frac{\\lambda }{m}{{\\theta }_{j}} \\\\ \n",
    " & \\text{          }\\!\\!\\}\\!\\!\\text{ } \\\\ \n",
    " & Repeat \\\\ \n",
    "\\end{align}\n",
    "\n",
    "以下是原始代码是使用for循环的梯度函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_with_loop(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "    \n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "        \n",
    "        if (i == 0):\n",
    "            grad[i] = np.sum(term) / len(X)\n",
    "        else:\n",
    "            grad[i] = (np.sum(term) / len(X)) + ((learningRate / len(X)) * theta[:,i])\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量化的梯度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    grad = ((X.T * error) / len(X)).T + ((learningRate / len(X)) * theta)\n",
    "    \n",
    "    # intercept gradient is not regularized\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
    "    \n",
    "    return np.array(grad).ravel()\n",
    "def gradient2(theta,x,y,lmd):\n",
    "    m = x.shape[0]\n",
    "    theta = theta.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    grad = x.T @ (sigmoid(x@theta) - y)/m\n",
    "    grad[1:,:] = grad[1:,:] + lmd*theta[1:,:]/m\n",
    "    return grad.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经定义了代价函数和梯度函数，现在是构建分类器的时候了。 对于这个任务，我们有10个可能的类，并且由于逻辑回归只能一次在2个类之间进行分类，我们需要多类分类的策略。 在本练习中，我们的任务是实现一对一全分类方法，其中具有k个不同类的标签就有k个分类器，每个分类器在“类别 i”和“不是 i”之间决定。 我们将把分类器训练包含在一个函数中，该函数计算10个分类器中的每个分类器的最终权重，并将权重返回为k X（n + 1）数组，其中n是参数数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def one_vs_all(X, y, num_labels, learning_rate):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    \n",
    "    # k X (n + 1) array for the parameters of each of the k classifiers\n",
    "    all_theta = np.zeros((num_labels, params + 1))\n",
    "    \n",
    "    # insert a column of ones at the beginning for the intercept term\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    \n",
    "    # labels are 1-indexed instead of 0-indexed\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(params + 1)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        y_i = np.reshape(y_i, (rows, 1))\n",
    "        \n",
    "        # minimize the objective function\n",
    "        fmin = minimize(fun=lrCostFunction, x0=theta, args=(X, y_i, learning_rate), method='TNC', jac=gradient2)\n",
    "        all_theta[i-1,:] = fmin.x\n",
    "    \n",
    "    return all_theta,fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要注意的几点：首先，我们为theta添加了一个额外的参数（与训练数据一列），以计算截距项（常数项）。 其次，我们将y从类标签转换为每个分类器的二进制值（要么是类i，要么不是类i）。 最后，我们使用SciPy的较新优化API来最小化每个分类器的代价函数。 如果指定的话，API将采用目标函数，初始参数集，优化方法和jacobian（渐变）函数。 然后将优化程序找到的参数分配给参数数组。\n",
    "\n",
    "实现向量化代码的一个更具挑战性的部分是正确地写入所有的矩阵，保证维度正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 1), (401,), (10, 401))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = data['X'].shape[0]\n",
    "params = data['X'].shape[1]\n",
    "\n",
    "all_theta = np.zeros((10, params + 1))\n",
    "\n",
    "X = np.insert(data['X'], 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "theta = np.zeros(params + 1)\n",
    "\n",
    "y_0 = np.array([1 if label == 0 else 0 for label in data['y']])\n",
    "y_0 = np.reshape(y_0, (rows, 1))\n",
    "\n",
    "X.shape, y_0.shape, theta.shape, all_theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，theta是一维数组，因此当它被转换为计算梯度的代码中的矩阵时，它变为（1×401）矩阵。 我们还检查y中的类标签，以确保它们看起来像我们想象的一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['y'])#看下有几类标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们确保我们的训练函数正确运行，并且得到合理的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.38336222e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.30430557e-03, -7.26793809e-10,  0.00000000e+00],\n",
       "       [-3.18324611e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         4.45381262e-03, -5.07780661e-04,  0.00000000e+00],\n",
       "       [-4.79997519e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -2.87321309e-05, -2.47249198e-07,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-7.98766437e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -8.94366955e-05,  7.20995431e-06,  0.00000000e+00],\n",
       "       [-4.57241623e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.33645939e-03,  9.99306115e-05,  0.00000000e+00],\n",
       "       [-5.40553440e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.16460414e-04,  7.85209496e-06,  0.00000000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_theta,f = one_vs_all(data['X'], data['y'], 10, 1)\n",
    "all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: array([[0.02014754]])\n",
       "     jac: array([ 2.35055608e-07,  0.00000000e+00,  0.00000000e+00,  5.15689830e-14,\n",
       "       -6.49518072e-13,  2.97232126e-12,  4.94674301e-12, -2.85110315e-11,\n",
       "        1.46902905e-10,  3.99961392e-10,  1.44742398e-10,  2.49938703e-11,\n",
       "        6.52847203e-11,  1.02391045e-10, -3.56219731e-10, -4.04614555e-10,\n",
       "       -4.15334765e-11, -3.10566547e-12, -4.05741689e-14,  6.41316581e-14,\n",
       "        0.00000000e+00,  4.65720240e-14, -6.07383941e-13, -8.63570549e-12,\n",
       "        7.30753753e-11,  2.97379356e-10,  4.53957774e-10,  8.50618832e-10,\n",
       "        1.91611052e-09,  3.13657715e-09,  4.00865666e-09,  1.62708706e-09,\n",
       "       -1.06593490e-09, -1.93455237e-09,  3.39303182e-09,  4.63973670e-09,\n",
       "        1.43556292e-09, -4.50494747e-10, -2.76281226e-10,  3.08771786e-12,\n",
       "       -1.90863399e-12, -4.00957195e-13,  6.00487566e-12,  3.31948267e-11,\n",
       "       -4.31350567e-10, -1.96702983e-09,  2.92727911e-09,  1.37738516e-08,\n",
       "        1.93842279e-08,  1.11004675e-08,  6.22939314e-09,  6.59485256e-09,\n",
       "        8.27716740e-09, -2.61533301e-09, -1.17900847e-08, -3.30573027e-08,\n",
       "       -1.20969794e-08,  1.57691823e-08, -1.24734706e-09,  1.08453894e-09,\n",
       "        3.19069404e-10, -1.70300231e-12,  1.53768715e-11,  4.32457868e-10,\n",
       "       -3.98255260e-09, -1.60274054e-08,  1.32499790e-08,  5.58056235e-08,\n",
       "        7.81979653e-08,  7.85646625e-08,  5.20540292e-08,  2.32154419e-08,\n",
       "        4.74259639e-08, -2.20282420e-08, -2.52151349e-08,  1.58004622e-08,\n",
       "        1.75256653e-08,  2.04820033e-08,  3.21977917e-08, -9.77609652e-09,\n",
       "       -2.54027178e-09, -6.90542508e-12, -1.01411874e-10,  4.64504351e-09,\n",
       "        1.25936425e-09, -1.85357269e-08,  2.22724762e-08,  5.19793095e-08,\n",
       "        4.78713147e-08,  5.10247388e-08,  8.79705913e-08,  1.29922154e-07,\n",
       "        4.20675548e-08, -1.52905015e-08,  3.39634188e-08,  5.57120584e-08,\n",
       "        8.37229401e-08,  1.08128689e-07,  4.26178744e-08, -2.14083435e-08,\n",
       "       -5.17746699e-09,  1.65015297e-11,  4.21532164e-10,  1.21978428e-09,\n",
       "       -2.37659270e-08, -5.67557604e-08,  5.60904290e-09,  1.25126683e-08,\n",
       "        1.17130242e-07,  3.89382912e-08, -2.31259078e-08, -1.01043569e-07,\n",
       "       -7.78509954e-08, -1.40812708e-07, -1.23923341e-09, -4.70498375e-08,\n",
       "        1.15308105e-07,  1.91273332e-07,  7.04473104e-08, -2.20945222e-09,\n",
       "       -1.74437675e-09,  8.36146930e-10, -7.29336072e-09, -2.87272285e-08,\n",
       "       -4.70340877e-08, -6.78478263e-08, -6.93208810e-08, -2.39782479e-08,\n",
       "       -2.34231448e-08, -1.16376304e-07, -1.07888902e-07, -2.34526314e-07,\n",
       "       -3.90151224e-08, -3.13230298e-08, -6.15454235e-09, -1.47289944e-07,\n",
       "       -9.21760933e-08,  1.41993283e-07,  1.47874735e-07,  3.71863323e-08,\n",
       "        3.39317084e-09,  9.27102030e-10, -9.47122005e-09, -2.42529324e-08,\n",
       "       -6.99129184e-08, -1.30834203e-07,  1.92604931e-08,  7.98545310e-08,\n",
       "       -1.22017494e-08, -6.38874752e-08, -2.93135832e-08,  4.85414074e-08,\n",
       "        1.04325722e-07,  1.42257771e-07, -7.62890837e-09, -1.02740581e-07,\n",
       "       -7.83301586e-08,  1.95292507e-07,  1.49963130e-07,  1.18877016e-08,\n",
       "        1.01459127e-08, -7.59636736e-10,  8.12323506e-09, -3.53725866e-08,\n",
       "       -6.58888902e-08, -1.19716741e-08, -2.22037918e-08,  1.01093594e-08,\n",
       "        5.24089684e-08,  1.64854031e-07,  1.38475823e-07,  1.31825427e-07,\n",
       "        8.39641765e-08,  4.35686887e-08,  6.56154791e-08, -1.09887065e-07,\n",
       "        7.99561111e-08,  1.33933843e-07,  1.08351505e-07,  1.75666531e-08,\n",
       "        1.81058426e-08, -4.88560564e-10,  2.35013515e-08, -6.48855664e-09,\n",
       "       -1.16424522e-07,  2.92322149e-08, -6.57127044e-09, -1.09854671e-07,\n",
       "        1.00217225e-07,  2.73105435e-07,  1.87751013e-07,  2.16706791e-08,\n",
       "        1.78985357e-08,  3.25130271e-09, -1.46966612e-07,  6.53596897e-08,\n",
       "       -3.07760802e-08,  1.04978744e-07,  8.85212026e-08,  2.22528981e-08,\n",
       "        2.61524858e-08,  1.06067345e-09,  2.48165790e-08, -3.63445259e-08,\n",
       "        3.17556828e-08, -3.09478289e-08, -1.81201323e-07, -4.15123406e-08,\n",
       "        1.94710466e-07,  2.46298826e-07,  4.64998702e-08,  2.75596242e-08,\n",
       "       -2.49499494e-08, -1.35717749e-07, -1.20278753e-07, -9.84446320e-08,\n",
       "        1.63305198e-07, -6.02687071e-09,  8.13358559e-08,  2.43636850e-08,\n",
       "        2.60599515e-08, -4.51495041e-09, -2.25804984e-08, -8.78342900e-08,\n",
       "        6.87157704e-08,  1.53244936e-07, -9.08282397e-08, -2.32679618e-09,\n",
       "        2.65046003e-07,  1.08074166e-07, -1.20784661e-08, -4.56299207e-08,\n",
       "       -1.03089404e-07, -1.56584709e-07, -3.58346527e-08,  3.81716186e-08,\n",
       "        2.64801748e-08,  5.61723800e-09,  1.06743718e-07,  4.19562131e-08,\n",
       "        1.93239128e-08,  4.75626140e-09, -6.91510629e-08, -1.40354179e-07,\n",
       "       -2.96322867e-08,  2.08781983e-07,  1.54409669e-07,  1.72688202e-07,\n",
       "        2.60492004e-07,  8.01897797e-08,  1.44574200e-08,  2.55055868e-08,\n",
       "       -6.33586119e-08, -1.70034991e-07, -1.74026071e-07, -1.37832036e-07,\n",
       "       -1.34164523e-07,  5.19846677e-08,  8.70160442e-08,  3.23704666e-08,\n",
       "        1.46442054e-08,  2.70277989e-09, -2.44548170e-08, -1.13113626e-07,\n",
       "       -8.64771047e-08,  1.40659605e-07,  1.83479685e-07,  2.82001582e-07,\n",
       "        1.71854805e-07,  1.68550808e-07,  1.35653364e-07,  1.31363794e-07,\n",
       "       -7.50463991e-08, -3.80956943e-07, -4.01177948e-07, -2.14312651e-07,\n",
       "        2.16826931e-08,  4.17086580e-08, -4.28604118e-09,  8.66615385e-09,\n",
       "        4.00281611e-09, -2.09557994e-09,  8.20758242e-09, -1.95804439e-08,\n",
       "       -9.05982844e-08,  7.07951646e-08,  1.71716187e-07,  1.97147226e-07,\n",
       "        1.97062642e-07,  1.65360000e-07,  1.01035748e-07, -9.37475479e-10,\n",
       "       -2.56053088e-07, -4.84206643e-07, -2.49456475e-07, -1.45581934e-08,\n",
       "        1.13623302e-07,  3.80730913e-08,  2.52088264e-08,  2.56800455e-08,\n",
       "        3.45911950e-09, -1.23354059e-09,  9.22222997e-09,  6.15862538e-09,\n",
       "        3.92420875e-08, -4.51985458e-08,  6.66018853e-08,  1.21802618e-07,\n",
       "        1.05620622e-07,  4.05287815e-08, -2.12417029e-08, -1.39151053e-07,\n",
       "       -1.70240850e-07, -6.90967418e-08,  2.06258576e-07,  1.99363284e-07,\n",
       "        1.06393335e-07,  4.19506640e-08,  3.73423370e-08,  4.64437695e-08,\n",
       "        2.25083389e-08, -6.70105383e-11,  1.54783981e-09,  6.02975170e-09,\n",
       "        4.73344011e-09,  3.56662016e-08, -5.71628550e-08, -4.27771471e-09,\n",
       "        2.12670847e-08,  5.11345442e-08, -6.51785194e-09, -7.02036773e-08,\n",
       "        6.56188018e-08,  1.33727709e-07,  1.07439939e-07,  6.10889066e-08,\n",
       "        2.70497096e-08,  3.18716334e-09, -2.20823351e-09,  1.74251645e-08,\n",
       "        1.16283687e-08,  9.35278586e-12, -6.20092660e-10,  6.12403966e-09,\n",
       "        1.24331465e-08, -2.98353463e-09, -5.64827632e-08, -2.89658727e-08,\n",
       "       -2.12175291e-08, -1.61790695e-08,  1.39772090e-08,  3.40997045e-08,\n",
       "        4.30560849e-08,  1.78002988e-08, -2.11662283e-09,  6.73971494e-09,\n",
       "        3.00033355e-09, -7.50017463e-10, -1.18215068e-09,  8.32487897e-10,\n",
       "       -5.50819609e-11,  1.57692740e-13, -3.84026316e-11,  1.91157246e-10,\n",
       "        1.54539689e-09,  1.20089984e-08,  2.09194800e-08,  2.13027009e-08,\n",
       "        1.27260545e-09,  5.52257991e-09, -1.17459871e-08, -1.36720529e-08,\n",
       "       -2.56426283e-08, -3.85045122e-08, -1.18897603e-08,  1.27198412e-09,\n",
       "        9.84429016e-10,  7.00494512e-10,  5.20805770e-11, -2.14775082e-10,\n",
       "       -1.05988063e-10,  0.00000000e+00,  3.64655375e-12,  1.30390400e-11,\n",
       "       -9.41066785e-10,  6.35461723e-09,  7.38088997e-09,  8.49539547e-09,\n",
       "        1.87300096e-09,  1.10009763e-09,  1.11575978e-09,  1.26949339e-09,\n",
       "        2.25433362e-09,  3.46827813e-09,  1.00241508e-09,  3.36068406e-10,\n",
       "        6.68885424e-10,  3.48564331e-10,  2.87137040e-11, -5.59936089e-12,\n",
       "        0.00000000e+00])\n",
       " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
       "    nfev: 98\n",
       "     nit: 13\n",
       "  status: 1\n",
       " success: True\n",
       "       x: array([-5.40553440e+00,  0.00000000e+00,  0.00000000e+00, -2.09489107e-09,\n",
       "       -6.70726628e-06,  7.49655766e-05,  7.09569844e-04,  2.25796834e-04,\n",
       "        6.09320400e-05, -1.41047034e-04, -1.06428718e-03, -2.22848748e-04,\n",
       "        2.69285793e-04,  4.62272747e-04,  2.71872907e-03,  2.36643061e-03,\n",
       "        1.32912850e-05,  8.55475835e-06,  3.21422444e-07, -2.06139100e-07,\n",
       "        0.00000000e+00, -1.51548270e-09, -8.75771821e-06, -1.47141659e-05,\n",
       "        1.09870421e-03,  1.99802411e-03, -5.50952414e-03,  2.30981107e-03,\n",
       "        4.92076493e-03,  2.88088448e-03,  1.20707916e-02,  8.35526452e-03,\n",
       "        5.87216427e-03,  2.09954032e-03, -2.00837319e-02, -2.39588114e-02,\n",
       "       -2.68814902e-03,  3.55388796e-03,  2.89384439e-03, -1.24434471e-04,\n",
       "        8.19941122e-07,  1.37676146e-08,  5.47982256e-05, -4.71426781e-05,\n",
       "       -4.89245617e-03, -1.90690248e-02, -3.47670614e-02, -4.90729366e-02,\n",
       "       -7.92532292e-02, -1.24364288e-01, -1.53522794e-01, -2.24459373e-01,\n",
       "       -2.70540245e-01, -2.15790524e-01, -3.42896189e-01, -2.31492751e-01,\n",
       "        2.18024074e-02, -1.45512231e-02, -4.39688570e-02,  5.71090724e-03,\n",
       "        1.22942554e-03,  4.54999567e-08,  4.73053014e-04,  2.04163735e-03,\n",
       "       -6.47320786e-02, -1.69826639e-01, -1.78654940e-01, -2.67207744e-01,\n",
       "       -2.30277807e-01, -1.43484616e-01,  6.86854791e-02,  2.76781109e-01,\n",
       "        4.30634444e-02, -3.81684711e-03, -2.01928756e-01, -1.71129463e-01,\n",
       "        2.57210947e-01,  1.31396084e-01,  2.55589528e-02, -3.34288628e-02,\n",
       "       -1.02416434e-02, -1.22789658e-05,  6.68605435e-04,  5.87290137e-03,\n",
       "       -1.07938875e-01, -2.91227229e-01, -1.66099898e-01, -2.10681594e-01,\n",
       "       -1.80160904e-01,  3.41850694e-01,  6.25022319e-01,  9.44842133e-01,\n",
       "        4.65575969e-01,  5.53891245e-01,  4.22456307e-01, -1.61481856e-01,\n",
       "        4.18879778e-01,  5.72854463e-01,  7.12768378e-02, -1.09696135e-01,\n",
       "       -3.25299979e-02, -6.70474029e-05,  2.05352753e-03, -1.09349501e-02,\n",
       "       -1.67911435e-01, -3.74146704e-01, -3.10457039e-01, -6.87333132e-01,\n",
       "       -2.90646729e-01,  2.54729590e-01,  1.22731101e-01,  5.95973915e-01,\n",
       "        1.06597630e+00,  4.15907633e-01,  9.51674721e-01,  1.61614637e-01,\n",
       "       -2.05948847e-01, -6.81024789e-01, -3.24794959e-01, -1.77029293e-01,\n",
       "       -3.06189051e-02,  2.15132750e-03, -1.69860130e-02, -1.89498208e-01,\n",
       "       -4.26927096e-01, -5.78382745e-01, -3.25376038e-01, -6.01595375e-01,\n",
       "        1.36237320e-01, -8.99807523e-02, -2.34500637e-03,  1.03810029e-01,\n",
       "        5.70009217e-01,  2.41667551e-01,  1.97071530e-01,  1.28358224e-01,\n",
       "        6.34377045e-02,  7.73045754e-02, -4.83446708e-01, -3.56594845e-01,\n",
       "       -2.49424749e-02,  2.79782861e-03, -2.32742827e-02, -4.63528800e-01,\n",
       "       -5.37862953e-01, -7.44603343e-02,  2.75804940e-01, -1.26606483e-01,\n",
       "       -6.05121809e-02,  6.11847564e-02,  5.20640386e-01,  8.54961801e-01,\n",
       "        1.40280979e-01,  7.30943531e-01,  1.02332280e-01,  1.13443537e+00,\n",
       "        5.93446940e-01,  1.01061091e+00, -1.16926086e-01, -7.78225500e-01,\n",
       "       -1.09349997e-01,  1.02187901e-03, -1.39346238e-02, -6.77801235e-01,\n",
       "       -2.69804520e-01, -1.10462212e-01, -1.43527784e-01, -3.58566603e-01,\n",
       "       -7.51493434e-02,  2.08944838e-01, -1.54267510e-01,  5.36755450e-01,\n",
       "        3.02989804e-01,  5.43113433e-01,  4.57125480e-01,  9.51968366e-01,\n",
       "        2.97190441e-01,  1.01075891e+00,  5.78267847e-02, -6.21572063e-01,\n",
       "       -1.59492607e-01,  3.04345626e-04, -5.61939765e-02, -3.48245445e-01,\n",
       "        3.49644301e-01,  1.25454449e-01,  3.48037142e-01,  3.79010714e-01,\n",
       "        2.12753541e-01, -3.97314846e-01, -6.99787715e-01,  1.59618761e-03,\n",
       "       -1.38282203e+00, -1.57977106e+00, -8.99872853e-01, -3.52622486e-02,\n",
       "       -3.92529647e-01,  1.08748793e+00, -6.67581735e-02, -3.81412527e-01,\n",
       "       -1.36961879e-01, -3.67345337e-03, -6.41764664e-02,  4.40922268e-03,\n",
       "        4.53794952e-01, -1.05194437e-01,  2.69643530e-01,  5.15582297e-01,\n",
       "       -8.29708018e-02, -6.78584273e-01, -1.36090348e+00, -2.03460848e+00,\n",
       "       -2.35769604e+00, -1.15008184e+00, -7.73329320e-01, -1.11610213e+00,\n",
       "        2.31314590e-01,  4.93089588e-01, -1.90308017e-01, -5.99342309e-01,\n",
       "       -5.41916002e-02, -7.89618227e-03, -1.97085816e-01, -4.60995741e-01,\n",
       "        2.34215129e-01,  4.73284876e-01,  3.30723800e-01, -1.28808824e-01,\n",
       "       -3.61069772e-01, -8.49079039e-01, -1.57363343e+00, -1.50399444e+00,\n",
       "       -5.88798821e-01, -6.69239442e-01, -2.79657429e-01, -4.80918954e-01,\n",
       "        1.37863790e-01, -3.52534698e-01, -1.96467584e-01, -3.77475168e-01,\n",
       "        1.37122663e-02,  2.60581342e-02, -3.70977867e-01, -2.86281797e-01,\n",
       "        9.86323893e-03,  1.46306192e-01,  7.52710531e-01,  9.10441518e-02,\n",
       "        6.26098564e-01,  2.26540178e-01, -2.35012205e-01, -4.50411427e-02,\n",
       "       -4.68683391e-01, -1.41086528e-01, -1.89976545e-01, -3.63362863e-01,\n",
       "       -1.01557031e+00, -2.61278039e-01, -5.71688384e-02, -1.34825694e-01,\n",
       "       -2.99524748e-03,  1.60555183e-02, -1.82089284e-01, -1.30906647e-01,\n",
       "        9.22732235e-03, -3.28336957e-02,  5.74773981e-01,  7.09867907e-01,\n",
       "        1.05527323e+00,  6.05159099e-01, -4.00139689e-01, -3.33380232e-01,\n",
       "       -8.64059591e-02,  1.15492723e-01, -1.04710743e-01, -6.04669960e-01,\n",
       "       -7.92336374e-01,  1.31436376e-01, -1.42352735e-01, -1.41325408e-01,\n",
       "        5.69607400e-03,  3.33575789e-05, -3.38233971e-02, -1.72947416e-01,\n",
       "        6.37408725e-03,  5.96971252e-01,  1.64856120e-01, -6.75659737e-01,\n",
       "        2.28138644e-01,  5.58573346e-01, -2.35271185e-01, -1.98374452e-01,\n",
       "        1.65115467e-01, -1.97367928e-01,  3.85994695e-02, -6.94616401e-01,\n",
       "       -2.43975256e-01,  3.09014558e-02, -4.73360736e-01, -1.84593477e-01,\n",
       "       -6.35267343e-03,  4.82795496e-04, -8.19403938e-03, -3.46468455e-01,\n",
       "       -2.49062585e-01,  4.07708296e-01, -2.32386785e-01,  1.24047808e-01,\n",
       "        8.02898092e-01,  5.41619842e-01, -7.72457620e-02,  4.12265112e-02,\n",
       "       -1.17618344e-01,  4.02594895e-01,  4.12774505e-01, -3.35278648e-01,\n",
       "        5.36609666e-02, -1.82639035e-01, -2.79980557e-01, -1.84445739e-01,\n",
       "       -7.95312831e-02,  1.85040919e-04, -3.01957354e-04, -8.39802236e-02,\n",
       "       -5.26718970e-02, -9.76273087e-02, -1.92324668e-01,  7.86319244e-02,\n",
       "        7.07495175e-01,  5.52201804e-01,  5.41495125e-01,  8.41906448e-01,\n",
       "        4.42757238e-01,  1.02782712e-01, -6.67701011e-01, -6.62960312e-01,\n",
       "       -4.58078630e-01, -2.66877467e-01, -5.97809727e-02, -1.03519703e-01,\n",
       "       -4.80250773e-02, -2.18369112e-05, -4.30185983e-03,  3.83838625e-02,\n",
       "        1.73777996e-01, -3.67050117e-01, -4.23046221e-01, -1.58629873e-02,\n",
       "        9.22145269e-02,  9.68307270e-02,  3.87160032e-01,  4.68466991e-01,\n",
       "        3.19289984e-01, -3.10440692e-01, -5.28765712e-01, -4.76659737e-01,\n",
       "       -3.10178013e-01, -1.56197651e-01, -3.75413627e-03, -9.70468427e-03,\n",
       "       -2.31154205e-04, -2.94615352e-08,  1.81688652e-04,  1.93853318e-03,\n",
       "       -1.52171539e-02, -3.11346061e-01, -3.64079450e-01, -1.88995749e-01,\n",
       "       -7.91436222e-02, -3.35330671e-02, -7.65771543e-02, -7.68514415e-02,\n",
       "       -1.70209013e-01, -2.29460260e-01, -6.28951598e-02,  1.24061436e-02,\n",
       "        1.46951787e-02,  6.54805662e-03,  5.70474437e-04,  1.44938086e-03,\n",
       "        4.91376793e-04,  0.00000000e+00, -9.23488502e-06, -4.21498921e-05,\n",
       "        5.36663656e-03, -6.96722613e-02, -5.04154562e-03, -2.13719913e-02,\n",
       "        1.39518605e-03,  3.96437841e-03,  6.30248800e-03,  4.68541843e-03,\n",
       "        1.29054539e-02,  2.01901298e-02,  7.06924746e-03,  9.63285723e-04,\n",
       "        1.48599807e-03,  1.16314810e-04, -1.16460414e-04,  7.85209496e-06,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在准备好最后一步 - 使用训练完毕的分类器预测每个图像的标签。 对于这一步，我们将计算每个类的类概率，对于每个训练样本（使用当然的向量化代码），并将输出类标签为具有最高概率的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_all(X, all_theta):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    num_labels = all_theta.shape[0]\n",
    "    \n",
    "    # same as before, insert ones to match the shape\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    \n",
    "    # convert to matrices\n",
    "    X = np.matrix(X)\n",
    "    all_theta = np.matrix(all_theta)\n",
    "    \n",
    "    # compute the class probability for each class on each training instance\n",
    "    h = sigmoid(X * all_theta.T)\n",
    "    \n",
    "    # create array of the index with the maximum probability\n",
    "    h_argmax = np.argmax(h, axis=1)\n",
    "    \n",
    "    # because our array was zero-indexed we need to add one for the true label prediction\n",
    "    h_argmax = h_argmax + 1\n",
    "    \n",
    "    return h_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以使用predict_all函数为每个实例生成类预测，看看我们的分类器是如何工作的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 94.46%\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_all(data['X'], all_theta)\n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, data['y'])]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print ('accuracy = {0}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下一个练习中，我们将介绍如何从头开始实现前馈神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络模型图示\n",
    "<img style=\"float: left;\" src=\"../img/nn_model.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
